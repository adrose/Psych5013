---
title: "Quiz 2"
author: "Adon Rosen"
date: 'Date: `r Sys.Date()`'
output: pdf_document
---
  
```{r, echo=F, message=F, warning=FALSE}
library(knitr)
opts_knit$set(root.dir='./')  #Don't combine this call with any other chunk -especially one that uses file paths.
```


<!-- Set the report-wide options, and point to the external code file. -->
```{r set_options, echo=F, warning=FALSE}
# cat("Working directory: ", getwd())
report_render_start_time <- Sys.time()
opts_chunk$set(
  results    = 'show',
  comment    = NA,
  tidy       = FALSE,
  fig.width  = 10,
  fig.height = 6,
  fig.path   = 'figure-png/'
)
# echoChunks <- FALSE
options(width=80) #So the output is 50% wider than the default.
read_chunk("./Quiz3.R") #This allows knitr to call chunks tagged in the underlying *.R file.
```


```{r load-packages, echo=FALSE, results='show', message=FALSE, warning=FALSE}
```
```{r load-data, echo=FALSE, results='show', message=FALSE, warning=FALSE}
```
```{r declare-functions, echo=FALSE, results='show', message=FALSE, warning=FALSE}
```



# Question 1
 (29 points) The following data consists of a 3 (age) x 2 (sex) natural design in which the proportion 
of pretend play between parents and infants changes as a function of age.  The DV (Y) is the observed 
proportion of parent-infant play that consists of pretend play.  The first independent variable (X1) is age, 
where 1 = 7-month old infants; 2 = 10-month old infants; and 3 = 13-month-old infants.   The second 
independent variable (X2) is sex, where 1=girls and 2=boys.   There are 8 infants in each cell of the 
design.  

## a.
```{r q-1-a, echo=FALSE, results='show', message=FALSE, warning=FALSE}
```

## b.
The unbiased RMSE is: `r summary(model.out)$sigma`

The biased RMSE is: `r rmse(model.out)`

## c. 
```{r q-1-c, echo=FALSE, results='show', message=FALSE, warning=FALSE}
```
The F value is: `r f.val.age`

The p value is: `r p.val.age`

The models being compared are:

model full: $Y_{playtime}= \beta_{intercept} + \beta_{age} \times X_{i,age} + \epsilon_i$

model restricted: $Y_{playtime}=\beta_{intercept} + \epsilon_i$

## d. 
```{r q-1-d, echo=FALSE, results='show', message=FALSE, warning=FALSE}
```

The F value is: `r f.val.sex`

The p value is: `r p.val.sex`

## e.
The models being compared are

model full: $Y_{playtime}= \beta_{0} + \beta_{sex}\times X_{i,1}+\beta_{age}\times X_{i,2} + \beta_{sex\times age}\times X_{i,3} + \epsilon_i$
model restricted: $Y_{playtime}= \beta_{0} + \beta_{sex}\times X_{i,1}+\beta_{age}\times X_{i,2} + \epsilon_i$

## f.
While it is often inappropriate to drive model selection via significance in predictors (for instance, sex may be proven to be a signficiant predictor in the literature), the data suggest here that the most parasimounious model may be: $Y_{playtime}= \beta_{0} + \beta_{age}\times X_{i,2} +  \epsilon_i$, which is the model I would suggest given the data.

## g.
### Results from linear model with linear effect:

```{r q-1-g-lin, echo=FALSE, results='show', message=FALSE, warning=FALSE}
```

### Results from linear model with quadratic age effect:
```{r q-1-g-quad, echo=FALSE, results='show', message=FALSE, warning=FALSE}
```

### Results from ANOVA model with linear contrasts:
```{r q-1-g-linan, echo=FALSE, results='show', message=FALSE, warning=FALSE}
```

#### Results from ANOVA model with quadratic contrasts:
```{r q-1-g-quadan, echo=FALSE, results='show', message=FALSE, warning=FALSE}
```

Overall the linear model and the ANOVA models provide identical results: The linear effect explains a significant portion of the variance in the outcome; whereas, the quadratic effect does not. However, the linear model provides coefficients which can be used to interpret the magnitude of the effect. Specifically, for every increase in age unit playtime increases by .08 units.

## h.
```{r q-1-h, echo=FALSE, results='show', message=FALSE, warning=FALSE}
```

As tested in a linear model, we do not see a significant moderation effect between a linear age trend and sex (t(3,44)=.148, p=.88). The models being tested include:

model full: $Y_{playtime} = \beta_{0} + \beta_{sex} \times X_{i,sex} + \beta_{linearAge} \times X_{i,age} + \beta_{sex \times linearAge} \times X_{i,sex \times linearAge} + \epsilon_{i}$

model reduced: $Y_{playtime} = \beta_{0} + \beta_{sex} \times X_{i,sex} + \beta_{linearAge} \times X_{i,age} +  \epsilon_{i}$

# Question 2.
The two-way ANOVA, non-orthogonal case, has been a vexing problem 
for ANOVA researchers for many years.  Please answer the following questions concerning the two-
way non-orthogonal ANOVA. 

## a. 
The word orthogonal refers to a geometric phenomenon wherein the dot product of two vectors equals 0, or if $c_{i}^Tc_j=0$ where c refers to a set of vectors and $i\neg=j$.This occurs in a field of real numbers when these two vectors intersect with an angle of  $90^{\circ}$. This logic is applied to the design matrix in balanced ANOVA models. Orthogonality exists in balanced ANOVA designs when:

1) The sum of the coefficients in each linear contrast sums to 0

2) The sum of the products of the corresponding coefficients in any two contrast equals zero

However, when these are not satisfied, a design is said to be unbalanced or non-orthogonal. So the term non-orthogonal when used in context to ANOVA modeling, refers to the phenomenon when a design matrix does not have independece amongst it's cells in the design matrix.

## b.
Designs are non-orthognal when:

1) The sum of the coefficients in each linear contrast does not sums to 0

2) The sum of the products of the corresponding coefficients in any two contrast does not equals zero

One contributing factor is when data are unbalanced, so cells will have unequal representation from various populations being tested or are missing entire contrasts. 

## c.
Balanced ANOVA models display independence across the comparisons being made. So all forms of decomposing the models (i.e. Types I, II, & III sum of squares) provide identical solutions. For instance type I sum of squares is an ordered decomposition of the sum of squares, so models are tested in a consecutive fashion, but when the two main effects being tested display a large correlation across themselves, the variable fed into the model first will be given a larger weight to the model.

## d.
The Type I effects are the order dependent or the sequential sum-of-squres. Assuming the main effect of A was introduced into the model first, the order of tests would follow:

ME A:
R(A) = R() - A(A)

ME B:
R(B|A) = R(A) - R(B|A)

## e.
Type II tests assess the amount of variance a term adds when all terms are included except terms that contain the effect being tested. So the main effects of A and B would be tested as follows:

ME A:
R(A|B) = R(B) - R(A,B)

BE B:
R(B|A) = R(A) - R(A,B)

## f.
Type III tests assess the amount of variance a predictor adds when partialling out all additional covariates. So the main effects of A and B would be tested as follows:

ME A:
R(A|B) = R(B) - R(A,B)

BE B:
R(B|A) = R(A) - R(A,B)

## g.

Applebaum and Cramer (1972) suggest to use assess Type II effects when no moderation is present. This recommendation stems from the difficulty of interpreting two main effects when in the presence of an interaction.

## h.

Applebaum and Cramer (1972) highlight that when assessing Type I effects it is important to test for independence amongst the predictors. THis is important because if the predictors are confounded, only one predictor will be significant, wherein both are conveying similar information.

## i.

Anova and linear models are in essence identical modeling techniques. However they differ in that ANOVA models typically do not include intercept effects; whereas, linear models include an intercept and reference group coding.

# Question 3 

Consider the following  2-way ANOVA Table with the group number listed in the cells of the table.
$\begin{matrix} Factor & B=1 & B=2 & B=3 & B=4 \\ A=1 & Group = 1 & Group = 2 & Group =3 & Group = 4 \\ A = 2 & Group = 5 & Group = 6 & Group = 7 & Group = 8  \end{matrix}$

## a.
#### With intercept model:
```{r q-3-a, echo=FALSE, results='show', message=FALSE, warning=FALSE}
```

#### Cell mean model:
```{r q-3-a-2, echo=FALSE, results='show', message=FALSE, warning=FALSE}
```

## b. 
proc glm data = data; 

  class a b;
  
  model y = a b a*b; 
  
run;

## c.
proc glm data = data; 

  class a b;
  
  model y = a b a*b;
  
  contrast "ME A" a 1 -1;
  
  contrast "ME B" b 1 0 0 -1,
  
  0 1 0 -1,
  
  0 0 1 -1;
  
run;

## d.
proc glm data = data; 

  class a b;
  
  model y = a b a*b;
  
  contrast "linear B ME" b -1 -.5 .5 1;
  
run;
